{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnns.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg90deR13qYE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/044_cnn_transfer_learning/cnn_transfer_learning.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqxQlMm5PU5E"
      },
      "source": [
        "# Transfer Learning en Redes Convolucionales\n",
        "\n",
        "En posts anteriores hemos introducido la arquitectura de `red neuronal convolucional` y también hemos presentado varias arquitecturas famosas que han demostrado buenas prestaciones en multitud de tareas. Estas redes están formadas muchas capas convolucionales, algunas con más de 100 capas, lo cual significa que tienen muchos parámetros y entrenarlas desde cero puedes ser costoso. Sin embargo, existe una técnica que nos permite obtener buenos modelos con menores requisitos: el *transfer learning*. Ya hemos hablado anteriormente de esta técnica, en el contexto de modelos de lenguaje, pero la idea es la misma: utilizaremos el máximo número de capas de una red ya entrenada en otro dataset, y simplemente entrenaremos las nuevas capas que necesitemos para nuestra tarea concreta.\n",
        "\n",
        "![](https://pennylane.ai/qml/_images/transfer_learning_general.png)\n",
        "\n",
        "En este post vamos a ver cómo podemos utilizar una red neuronal pre-entrada en Imagenet, y adaptarla para una nueva tarea de clasificación con un pequeño dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r-GgLyOPU5I"
      },
      "source": [
        "## El dataset\n",
        "\n",
        "Nuestro objetivo será el de entrenar un clasificador de flores. Podemos descargar las imágenes de la siguiente url."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:19:56.174130Z",
          "start_time": "2020-09-12T19:19:52.964415Z"
        },
        "id": "kJvIo0A1PU5Q"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('flowers.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO8_d6f2PU5S"
      },
      "source": [
        "Una vez extraído el dataset, podemos ver que tenemos 5 clases de flores diferentes, distribuidas en 5 carpetas diferentes. Cada carpeta contiene varios ejemplos de flores de la categoría en cuestión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:19:56.190216Z",
          "start_time": "2020-09-12T19:19:56.177133Z"
        },
        "id": "9N91GpO8PU5T"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import torch "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C1wb2nXYboR"
      },
      "source": [
        "\n",
        "\n",
        "dir_path=\"/content/drive/MyDrive/basura\"\n",
        "classes = os.listdir(dir_path)\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOKZbx3CPU5W"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:19:56.221139Z",
          "start_time": "2020-09-12T19:19:56.196142Z"
        },
        "id": "HpUa77vBPU5X",
        "outputId": "2f054420-123b-4468-cb6b-9e00ec602077"
      },
      "source": [
        "imgs, labels = [], []\n",
        "\n",
        "for i, lab in enumerate(classes):\n",
        "  paths = os.listdir(f'{PATH}/{lab}')\n",
        "  print(f'Categoría: {lab}. Imágenes: {len(paths)}')\n",
        "  paths = [p for p in paths if p[-3:] == \"jpg\"]\n",
        "  imgs += [f'{PATH}/{lab}/{img}' for img in paths]\n",
        "  labels += [i]*len(paths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categoría: daisy. Imágenes: 769\n",
            "Categoría: dandelion. Imágenes: 1055\n",
            "Categoría: rose. Imágenes: 784\n",
            "Categoría: sunflower. Imágenes: 734\n",
            "Categoría: tulip. Imágenes: 984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4MHJj7qPU5c"
      },
      "source": [
        "Podemos visualizar algunas imágenes en el dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:19:57.159313Z",
          "start_time": "2020-09-12T19:19:56.222142Z"
        },
        "id": "Oit7EYpmPU5f"
      },
      "source": [
        "import random \n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(3,5, figsize=(10,6))\n",
        "for _ax in axs:\n",
        "  for ax in _ax:\n",
        "    ix = random.randint(0, len(imgs)-1)\n",
        "    img = io.imread(imgs[ix])\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(classes[labels[ix]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peYCSUPQPU5h"
      },
      "source": [
        "Vamos a crear también un subconjunto de test para poder comparar varios modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:19:57.485805Z",
          "start_time": "2020-09-12T19:19:57.160249Z"
        },
        "id": "sTzGQA2NPU5j",
        "outputId": "117b7c25-34e3-4220-b1c4-5b276998b034"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_imgs, test_imgs, train_labels, test_labels = train_test_split(imgs, labels, test_size=0.2, stratify=labels)\n",
        "\n",
        "len(train_imgs), len(test_imgs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3458, 865)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDJx_p31PU5k"
      },
      "source": [
        "Y por último creamos nuestros objetos `Dataset` y `DataLoader` para poder darle las imágenes a nuestros modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:28:52.577113Z",
          "start_time": "2020-09-12T19:28:52.570110Z"
        },
        "id": "UdQQMaHEPU5l"
      },
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, X, y, trans, device):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.trans = trans\n",
        "    self.device = device\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, ix):\n",
        "    # cargar la imágen\n",
        "    img = io.imread(self.X[ix])\n",
        "    # aplicar transformaciones\n",
        "    if self.trans:\n",
        "      img = self.trans(image=img)[\"image\"]\n",
        "    return torch.from_numpy(img / 255.).float().permute(2,0,1), torch.tensor(self.y[ix])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmOZ0BY_PU57"
      },
      "source": [
        "Nos aseguraremos que todas las imágenes del dataset tengan las mismas dimensiones: 224x224 píxeles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:28:53.617284Z",
          "start_time": "2020-09-12T19:28:53.601285Z"
        },
        "id": "F7PDI85mPU5-",
        "outputId": "8ba2c0cc-77d0-48fa-d710-62c78df61ada"
      },
      "source": [
        "import albumentations as A\n",
        "\n",
        "trans = A.Compose([\n",
        "    A.Resize(224, 224)\n",
        "])\n",
        "\n",
        "dataset = {\n",
        "    'train': Dataset(train_imgs, train_labels, trans, device), \n",
        "    'test': Dataset(test_imgs, test_labels, trans, device)\n",
        "}\n",
        "\n",
        "len(dataset['train']), len(dataset['test'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3458, 865)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:29:16.219339Z",
          "start_time": "2020-09-12T19:29:15.766097Z"
        },
        "id": "baTrUHwfPU6A"
      },
      "source": [
        "fig, axs = plt.subplots(3,5, figsize=(10,6))\n",
        "for _ax in axs:\n",
        "  for ax in _ax:\n",
        "    ix = random.randint(0, len(dataset['train'])-1)\n",
        "    img, lab = dataset['train'][ix]\n",
        "    ax.imshow(img.permute(1,2,0))\n",
        "    ax.axis('off')\n",
        "    ax.set_title(classes[lab])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:29:37.149917Z",
          "start_time": "2020-09-12T19:29:36.909560Z"
        },
        "id": "bezYn43gPU6B",
        "outputId": "fe54fe07-db54-464b-9255-060e5f0f07bd"
      },
      "source": [
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True, pin_memory=True), \n",
        "    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=256, shuffle=False)\n",
        "}\n",
        "\n",
        "imgs, labels = next(iter(dataloader['train']))\n",
        "imgs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 224, 224])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdtq6ZuKPU6D"
      },
      "source": [
        "## El Modelo\n",
        "\n",
        "Vamos a escoger la arquitectura `resnet`, de la que ya hablamos en el post anterior, para hacer nuestro clasificador. De este modelo usarmos todas las capas excepto la última, la cual sustituiremos por una nueva capa lineal para llevar a cabo la clasificación en 5 clases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:29:38.426725Z",
          "start_time": "2020-09-12T19:29:38.295912Z"
        },
        "id": "9NJJ0mryPU6F"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "resnext = models.resnext50_32x4d()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:29:39.219590Z",
          "start_time": "2020-09-12T19:29:39.203041Z"
        },
        "id": "9xdAebRZPU6H"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self, n_outputs=5, pretrained=False, freeze=False):\n",
        "    super().__init__()\n",
        "    # descargamos resnet\n",
        "    resnext = torchvision.resnext50_32x4d(pretrained=pretrained)\n",
        "    #resnet = torchvision.models.resnet18(pretrained=pretrained)\n",
        "    # nos quedamos con todas las capas menos la última\n",
        "    self.resnext = torch.nn.Sequential(*list(resnext.children())[:-1])\n",
        "    if freeze:\n",
        "      for param in self.resnext.parameters():\n",
        "        param.requires_grad=False\n",
        "    # añadimos una nueva capa lineal para llevar a cabo la clasificación\n",
        "    self.fc = torch.nn.Linear(512, 5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.resnext(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def unfreeze(self):\n",
        "    for param in self.resnext.parameters():\n",
        "        param.requires_grad=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:29:45.928257Z",
          "start_time": "2020-09-12T19:29:41.921301Z"
        },
        "id": "RFlIbI7ZPU6J",
        "outputId": "ed27fabf-6e28-4674-e7bb-f69adf18e34e"
      },
      "source": [
        "model = Model()\n",
        "outputs = model(torch.randn(64, 3, 224, 224))\n",
        "outputs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 5])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:29:48.568757Z",
          "start_time": "2020-09-12T19:29:48.554207Z"
        },
        "code_folding": [
          3
        ],
        "id": "hp03YDRJPU6M"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def fit(model, dataloader, epochs=5, lr=1e-2):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YV9-OHMPU6P"
      },
      "source": [
        "### Entrenando desde cero\n",
        "\n",
        "En primer lugar vamos a entrenar nuestro modelo desde cero para ver qué métricas podemos obtener."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:46:25.373418Z",
          "start_time": "2020-09-12T19:40:25.219570Z"
        },
        "id": "9mR6AbNrPU6Q"
      },
      "source": [
        "model = Model()\n",
        "fit(model, dataloader, epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FwO_S_9PU6R"
      },
      "source": [
        "Como puedes ver es complicado conseguir buenas métricas ya que nuestro dataset es muy pequeño."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDyknFrAPU6S"
      },
      "source": [
        "## Transfer Learning\n",
        "\n",
        "Ahora vamos a entrenar el mismo caso pero, en este caso, utilizando los pesos pre-entrenados de `resnet`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:33:13.447789Z",
          "start_time": "2020-09-12T19:31:48.895941Z"
        },
        "id": "7-3HZ8fsPU6S"
      },
      "source": [
        "model = Model(pretrained=True, freeze=True)\n",
        "fit(model, dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ9K_b6BPU6T"
      },
      "source": [
        "Como puedes ver no sólo obtenemos un mejor modelo en menos *epochs* sino que además cada *epoch* tarda menos en completarse. Esto es debido a que, al no estar entrenando gran parte de la red, los requisitos computacionales se reducen considerablemente. Mejores modelos y entrenados más rápido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXpJkAiZPU6U"
      },
      "source": [
        "## Fine Tuning\n",
        "\n",
        "Todavía podemos mejorar un poco más si, además de utilizar los pesos descargados de Imagenet en `resnet`, entrenamos también la red completa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:35:12.058029Z",
          "start_time": "2020-09-12T19:33:13.448788Z"
        },
        "id": "EukUbIBaPU6U"
      },
      "source": [
        "model = Model(pretrained=True, freeze=False)\n",
        "fit(model, dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0qtvse6PU6V"
      },
      "source": [
        "Es común entrenar primero el modelo sin entrenar la red pre-entrenada durante varias epochs y después seguir entrenando, pero permitiendo ahora la actualización de pesos también en la red pre-entrenada (usualmente con un *learning rate* más pequeño)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:38:34.921458Z",
          "start_time": "2020-09-12T19:35:12.059030Z"
        },
        "id": "lJdvoDGuPU6W"
      },
      "source": [
        "model = Model(pretrained=True, freeze=True)\n",
        "fit(model, dataloader)\n",
        "model.unfreeze()\n",
        "fit(model, dataloader, lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3RlIixGPU6X"
      },
      "source": [
        "Otra alternativa de *fine tuning* es la de entrenar el modelo con diferentes *learning rates*, uno para la red pre-entrenada y otro para las capas nuevas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-12T19:39:52.893295Z",
          "start_time": "2020-09-12T19:39:52.876296Z"
        },
        "id": "KcM8b6_YPU6X"
      },
      "source": [
        "optimizer = torch.optim.Adam([\n",
        "    {'params': model.resnext.parameters(), 'lr': 1e-4},\n",
        "    {'params': model.fc.parameters(), 'lr': 1e-3}\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXcCGD0_PU6Y"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "En este post hemos visto como podemos llevar a cabo *transfer learning* con redes convolucionales. Aplicar esta técnica nos permitirá obtener mejores modelos con menos requisitos computacionales y con datasets reducidos. Podemos descargar una red pre-entrenada con otro dataset (idealmente, un dataset similar al nuestro) y aprovechar el máximo número de capas. Podemos *congelar* la red pre-entrenada, de manera que no se actualicen sus pesos durante el entrenamiento, y utilizarla solo como extractor de características que las nuevas capas (las cuales si entrenamos) pueden aprovechar. Aún así, hacer *fine tuning* (seguir entrenando la red pre-entrenada) puede dar como resultado un mejor modelo. El *transfer learning* es una técnica muy potente que siempre que podamos podemos aprovechar para reducir los requisitos computacionales de nuestros modelos."
      ]
    }
  ]
}